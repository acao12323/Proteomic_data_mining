{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatic data minign\n",
    "The goal of this activity is to put into practice the bioinformatics dataa mining skills adquired so far, such as using APIs to access biological and chemical databases and leveraging specielized libraries for data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary library\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval information about proteins and chemical compounds\n",
    "\n",
    "I implemented a function that takes a list of Protein Data Bank (PDB) IDs as input and downloads the corresponding `.cif` files from the PDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIF file for 1tup downloaded successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base URL for PDB file requests\n",
    "base_url = \"https://www.rcsb.org/pdb/files/\"\n",
    "\n",
    "def cif_downloader(id_list, url):\n",
    "    \"\"\"\n",
    "    Downloads CIF files from the RCSB PDB for a given list of PDB IDs.\n",
    "    \n",
    "    Args:\n",
    "        id_list: A list of PDB IDs (strings)\n",
    "        url: A base url for file requests\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "        \n",
    "    for id in id_list:\n",
    "        # Construct the URL for the specific PDB ID\n",
    "        response = requests.get(f\"{base_url}{id}.cif\")\n",
    "        \n",
    "        # Check if the request was succesful\n",
    "        if response.status_code == 200:\n",
    "            # Save the CIF file in chuncks\n",
    "            with open(f\"{id}.cif\", \"wb\") as cif_file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    cif_file.write(chunk)\n",
    "            print(f\"CIF file for {id} downloaded successfully.\\n\")\n",
    "        else:\n",
    "            print(f\"Error ({response.status_code}) downloading CIF file for {id}.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "lista_ids_ejemplo = ['1tup']\n",
    "cif_downloader(lista_ids_ejemplo, base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, using the protein ID '1tup', its UniProt identifier is determined through the UniProt API. Once the identifier is obtained, the following information is extracted from UniProt and stored in a DataFrame:\n",
    "1. publication date\n",
    "2. last modification date\n",
    "3. review status (Swiss-Prot or TrEMBL)\n",
    "4. gene name and synonyms\n",
    "5. organism\n",
    "6. full protein name\n",
    "7. single-letter amino acid sequence\n",
    "8. associated PDB IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the data\n",
    "df_1tup = pd.DataFrame()\n",
    "\n",
    "# Construct the URL for the UniProt API search\n",
    "url_1tup = f'https://rest.uniprot.org/uniprotkb/search?query=1tup'\n",
    "\n",
    "# Send a GET request to the UniProt API\n",
    "response_1tup = requests.get(url_1tup)\n",
    "\n",
    "# Process the response data\n",
    "if response_1tup.status_code == 200:\n",
    "    data_1tup = response_1tup.json()\n",
    "\n",
    "    # Iterate over each result in the JSON response\n",
    "    for result in data_1tup[\"results\"]:\n",
    "        # Handle potential missing synonyms data\n",
    "        synonyms = result.get(\"genes\", [{}])[0].get(\"synonyms\", [])\n",
    "\n",
    "        # Create a new row for the DataFrame\n",
    "        new_row = {\n",
    "            'Uniprot_id': result[\"uniProtkbId\"],\n",
    "            'Publication_date': result[\"entryAudit\"][\"firstPublicDate\"],\n",
    "            'Modification_date': result[\"entryAudit\"][\"lastAnnotationUpdateDate\"],\n",
    "            'Reviewed': [\"True\" if \"Swiss-Prot\" in result[\"entryType\"] else \"False\"],\n",
    "            'Gene_name': result[\"genes\"][0][\"geneName\"][\"value\"],\n",
    "            'Synonyms': [synonyms if synonyms else None],\n",
    "            'Organism': result[\"organism\"][\"scientificName\"],\n",
    "            # Add the full protein name\n",
    "            'Protein_name': result[\"proteinDescription\"][\"recommendedName\"][\"fullName\"][\"value\"],\n",
    "            'PDB_ids': result[\"primaryAccession\"],\n",
    "        }\n",
    "\n",
    "        # Append the new row to the DataFrame\n",
    "        df_1tup = pd.concat([df_1tup, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "else:\n",
    "    print(f\"Error {response_1tup.status_code} occurred when fetching data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we investigate UniProt to determine if the '1tup' entry includes information about any cofactors. If a cofactor is identified, we utilize the PubChem API to extract the following data using its CID:\n",
    "1. PubChem compound identifier (CID)\n",
    "2. Exact molecular weight\n",
    "3. InChI\n",
    "4. InChIKey\n",
    "5. IUPAC names\n",
    "\n",
    "This information is then stored in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cofactor_name \u001b[38;5;241m=\u001b[39m data_1tup\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcofactors\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "cofactor_name = data_1tup.get(\"results\")[0].get(\"comments\")[1].get(\"cofactors\")[0].get(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cofactor information from UniProt data\n",
    "cofactor_name = data_1tup.get(\"results\")[0].get(\"comments\")[1].get(\"cofactors\")[0].get(\"name\")\n",
    "chebi_id = data_1tup.get(\"results\")[0].get(\"comments\")[1].get(\"cofactors\")[0].get(\"cofactorCrossReference\").get(\"id\")\n",
    "\n",
    "# Construct the PubChem API URL for the cofactor (CID 32051)\n",
    "url_cofactor = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/32051/JSON\"\n",
    "\n",
    "# Create an empty DataFrame to store cofactor data\n",
    "df_cofactor = pd.DataFrame()\n",
    "\n",
    "# Download cofactor information from PubChem\n",
    "response_cofactor = requests.get(url_cofactor)\n",
    "\n",
    "if response_cofactor.status_code == 200:\n",
    "    data_cofactor = response_cofactor.json()\n",
    "\n",
    "    # Extract desired information about the cofactor\n",
    "    new_row = {\n",
    "        \"Compound\": \"CHEBI:29105 - zinc(2+)\",  # Assuming this is static information\n",
    "\n",
    "        \"Pubchem_id\": data_cofactor.get(\"Record\").get(\"RecordNumber\"),\n",
    "\n",
    "        \"Peso_molecular\": data_cofactor.get(\"Record\").get(\"Section\")[2].get(\"Section\")[0].get(\"Section\")[0].get(\"Information\")[0].get(\"Value\").get(\"StringWithMarkup\")[0].get(\"String\"),\n",
    "        # Consider using a loop or list comprehension for potentially nested structures\n",
    "\n",
    "        \"Inchi\": data_cofactor.get(\"Record\").get(\"Section\")[1].get(\"Section\")[1].get(\"Section\")[1].get(\"Information\")[0].get(\"Value\").get(\"StringWithMarkup\")[0].get(\"String\"),\n",
    "        # Consider using a loop or list comprehension for potentially nested structures\n",
    "\n",
    "        \"Inchikey\": data_cofactor.get(\"Record\").get(\"Section\")[1].get(\"Section\")[1].get(\"Section\")[2].get(\"Information\")[0].get(\"Value\").get(\"StringWithMarkup\")[0].get(\"String\"),\n",
    "        # Consider using a loop or list comprehension for potentially nested structures\n",
    "\n",
    "        \"Iupac_name\": data_cofactor.get(\"Record\").get(\"Section\")[1].get(\"Section\")[1].get(\"Section\")[0].get(\"Information\")[0].get(\"Value\").get(\"StringWithMarkup\")[0].get(\"String\"),\n",
    "        # Consider using a loop or list comprehension for potentially nested structures\n",
    "    }\n",
    "\n",
    "    # Add the new row to the DataFrame\n",
    "    df_cofactor = pd.concat([df_cofactor, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Error {response_cofactor.status_code} occurred when fetching cofactor data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Biopython y rdkit son librerías muy útiles para manipular datos de origen biológico y químico, respectivamente.\n",
    "Utilízalas para completar estas tareas sobre el archivo 4ogq.cif: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reutilizamos la función creada en el punto 1\n",
    "descargar_cifs([\"4ogq\"])\n",
    "\n",
    "\"\"\"A. Parséalo con MMCIFParser() y guarda en una lista todas las heteromoléculas (sin incluir las aguas). (0,5)\"\"\"\n",
    "\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "parser = MMCIFParser(QUIET=True)\n",
    "structure = parser.get_structure('4ogq', \"./4ogq.cif\")\n",
    "\n",
    "heteromoleculas = []\n",
    "for modelo in structure:\n",
    "    for cadena in modelo:\n",
    "        for residuo in cadena:\n",
    "            if residuo.get_resname() != 'HOH': #Todas las heteromoleculas distintas a agua\n",
    "                heteromoleculas.append(residuo.id)\n",
    "\n",
    "print(f\"Hay {len(heteromoleculas)} heteromoleculas en la estructura (sin incluir las aguas)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"B. Parseálo con MMCIF2Dict() en un diccionario, extrae la información sobre la clave '_pdbx_entity_nonpoly' \n",
    "y guarda en un DataFrame la información sobre el nombre de cada una de las heteromoléculas,\n",
    "así como su identificador de tres letras. (0,5)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB.MMCIFParser import MMCIF2Dict\n",
    "import pandas as pd\n",
    "\n",
    "dic_4ogq = MMCIF2Dict(\"./4ogq.cif\")\n",
    "\n",
    "df_4ogp = pd.DataFrame({\"entitty_id\" : dic_4ogq.get(\"_pdbx_entity_nonpoly.entity_id\"),\n",
    "                        \"entity_name\" : dic_4ogq.get(\"_pdbx_entity_nonpoly.name\"),\n",
    "                        \"comp_id\" : dic_4ogq.get(\"_pdbx_entity_nonpoly.comp_id\")})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"C. Toma el nombre de cada heteromolécula y mediante la API de Pubchem consigue su SMILES,\n",
    "para los casos que sea posible.\n",
    "Transforma estos SMILES con rdkit en SDF y añade ambas columnas al DataFrame del Apartado 2B. (1)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "from rdkit import Chem    \n",
    "\n",
    "for index, row in df_4ogp.iterrows():\n",
    "    nombre = row[\"entity_name\"]\n",
    "\n",
    "    try:\n",
    "        # Buscamos en pubchem por el nombre de cada compuesto\n",
    "        compound = pcp.get_compounds(nombre, \"name\")\n",
    "\n",
    "        if compound:\n",
    "            # Tomamos el primer hallazgo de cada busqueda y buscamos los smiles\n",
    "            smiles = compound[0].isomeric_smiles\n",
    "            # Agregamos al df\n",
    "            df_4ogp.loc[index, \"smiles\"] = smiles\n",
    "            \n",
    "            # Convertimos a sdf\n",
    "            mol_smiles = Chem.MolFromSmiles(smiles)\n",
    "            sdf = Chem.MolToMolBlock(mol_smiles)\n",
    "            # Agregamos al df\n",
    "            df_4ogp.loc[index, \"SDF\"] = sdf\n",
    "            \n",
    "    except:\n",
    "        print(f\"Error en: {nombre}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"D. Genera un archivo .sdf en el cual guardes todas las moléculas SDF.\n",
    "Añade para cada una de ellas un campo que incluya información sobre su 'Molecular_weight'.\n",
    "Ayúdate de rdkit para calcular dicho campo y asegúrate que el archivo que has creado\n",
    "puede utilizarse para crear un objeto mol de rdkit con cada una de las moléculas. (1,5)\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actividad1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
